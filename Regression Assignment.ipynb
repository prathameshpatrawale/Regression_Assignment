{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31944a5d",
   "metadata": {},
   "source": [
    "\n",
    "1. What is Simple Linear Regression?  \n",
    "   - Simple Linear Regression models the relationship between a dependent variable (Y) and an independent variable (X) using a straight-line equation: Y = mX + c.\n",
    "\n",
    "2. What are the key assumptions of Simple Linear Regression?  \n",
    "   - Linearity – The relationship between X and Y is linear.  \n",
    "   - Independence – Observations are independent.  \n",
    "   - Homoscedasticity – Residuals have constant variance.  \n",
    "   - Normality – Residuals are normally distributed.\n",
    "\n",
    "3. What does the coefficient m represent in the equation Y = mX + c?  \n",
    "   - The coefficient m represents the slope, indicating the rate of change in Y for a one-unit increase in X.\n",
    "\n",
    "4. What does the intercept c represent in the equation Y = mX + c?  \n",
    "   - The intercept c is the value of Y when X = 0, providing a baseline for predictions.\n",
    "\n",
    "5. How do we calculate the slope m in Simple Linear Regression?  \n",
    "   \\[ m = \\frac{\\sum (X_i - \\bar{X})(Y_i - \\bar{Y})}{\\sum (X_i - \\bar{X})^2} \\]\n",
    "\n",
    "6. What is the purpose of the least squares method in Simple Linear Regression?  \n",
    "   - It minimizes the sum of squared residuals to find the best-fitting regression line.\n",
    "\n",
    "7. How is the coefficient of determination (R²) interpreted in Simple Linear Regression?  \n",
    "   - R² measures how well the independent variable explains the variation in the dependent variable, ranging from 0 to 1.\n",
    "\n",
    "8. What is Multiple Linear Regression?  \n",
    "   - It extends Simple Linear Regression by using multiple independent variables to predict a dependent variable.\n",
    "\n",
    "9. What is the main difference between Simple and Multiple Linear Regression?  \n",
    "   - Simple Linear Regression has one independent variable, while Multiple Linear Regression has two or more.\n",
    "\n",
    "10. What are the key assumptions of Multiple Linear Regression?  \n",
    "   - Linearity – Relationship between predictors and response is linear.  \n",
    "   - No Multicollinearity – Predictors should not be highly correlated.  \n",
    "   - Independence – Observations are independent.  \n",
    "   - Homoscedasticity – Residuals have constant variance.  \n",
    "   - Normality – Residuals are normally distributed.\n",
    "\n",
    "11. What is heteroscedasticity, and how does it affect the results of a Multiple Linear Regression model?  \n",
    "   Heteroscedasticity occurs when residual variance is not constant, leading to unreliable coefficient estimates.\n",
    "\n",
    "12. How can you improve a Multiple Linear Regression model with high multicollinearity?  \n",
    "   - Remove highly correlated predictors.  \n",
    "   - Use Principal Component Analysis (PCA).  \n",
    "   - Apply Ridge Regression or Lasso Regression.\n",
    "\n",
    "13. What are some common techniques for transforming categorical variables for use in regression models?  \n",
    "   - One-Hot Encoding  \n",
    "   - Label Encoding  \n",
    "   - Ordinal Encoding  \n",
    "   - Dummy Variables\n",
    "\n",
    "14. What is the role of interaction terms in Multiple Linear Regression?  \n",
    "   - Interaction terms capture the combined effect of two or more independent variables on the dependent variable.\n",
    "\n",
    "15. How can the interpretation of intercept differ between Simple and Multiple Linear Regression?  \n",
    "   - In Simple Linear Regression, the intercept represents Y when X = 0. In Multiple Linear Regression,\n",
    "    it represents Y when all independent variables are zero.\n",
    "\n",
    "16. What is the significance of the slope in regression analysis, and how does it affect predictions?  \n",
    "   - The slope indicates how much the dependent variable changes per unit increase in an independent variable.\n",
    "\n",
    "17. How does the intercept in a regression model provide context for the relationship between variables?  \n",
    "   - It provides a baseline value for predictions when all independent variables are zero.\n",
    "\n",
    "18. What are the limitations of using R² as a sole measure of model performance?  \n",
    "   - Does not indicate causation.  \n",
    "   - Can be artificially inflated by adding variables.  \n",
    "   - Does not account for overfitting.  \n",
    "   - Does not measure predictive accuracy.\n",
    "\n",
    "19. How would you interpret a large standard error for a regression coefficient?  \n",
    "   - A large standard error indicates high variability in the coefficient estimate, suggesting low reliability.\n",
    "\n",
    "20. How can heteroscedasticity be identified in residual plots, and why is it important to address it?  \n",
    "   - It appears as a funnel-shaped pattern in residual plots. Addressing it improves model reliability.\n",
    "\n",
    "21. What does it mean if a Multiple Linear Regression model has a high R² but low adjusted R²?  \n",
    "   - It suggests that additional predictors do not significantly improve the model and may be unnecessary.\n",
    "\n",
    "22. Why is it important to scale variables in Multiple Linear Regression?  \n",
    "   - Scaling ensures that variables with different units do not disproportionately affect the model.\n",
    "\n",
    "23. What is polynomial regression?  \n",
    "   - Polynomial regression models nonlinear relationships by introducing polynomial terms.\n",
    "\n",
    "24. How does polynomial regression differ from linear regression?  \n",
    "   - Linear regression fits a straight line, while polynomial regression fits a curve.\n",
    "\n",
    "25. When is polynomial regression used?  \n",
    "   - When the relationship between variables is nonlinear and cannot be captured by a straight line.\n",
    "\n",
    "26. What is the general equation for polynomial regression?  \n",
    "   - \\[ Y = a_0 + a_1X + a_2X^2 + ... + a_nX^n + \\epsilon \\]\n",
    "\n",
    "27. Can polynomial regression be applied to multiple variables?  \n",
    "   - Yes, Multivariate Polynomial Regression includes multiple independent variables.\n",
    "\n",
    "28. What are the limitations of polynomial regression?  \n",
    "   - Prone to overfitting.  \n",
    "   - Sensitive to outliers.  \n",
    "   - Higher-degree polynomials can be unstable.  \n",
    "   - Interpretability decreases with complexity.\n",
    "\n",
    "29. What methods can be used to evaluate model fit when selecting the degree of a polynomial?  \n",
    "   - Adjusted R²  \n",
    "   - Cross-validation  \n",
    "   - Residual plots  \n",
    "   - Akaike Information Criterion (AIC)\n",
    "\n",
    "30. Why is visualization important in polynomial regression?  \n",
    "   - It helps identify nonlinear patterns and assess model fit.\n",
    "\n",
    "31. How is polynomial regression implemented in Python?  \n",
    "\n",
    "   - from sklearn.preprocessing import PolynomialFeatures\n",
    "   - from sklearn.linear_model import LinearRegression\n",
    "   - from sklearn.pipeline import make_pipeline\n",
    "\n",
    "   - model = make_pipeline(PolynomialFeatures(degree=2), LinearRegression())\n",
    "   - model.fit(X_train, y_train)\n",
    "   - y_pred = model.predict(X_test)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b75db555",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
